<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>全卷积网络FCN | Acodey</title><meta name="author" content="acodey"><meta name="copyright" content="acodey"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="全卷积网络FCN详细讲解（超级详细哦）  1、全卷积网络（FCN）的简单介绍1.1、CNN与FCN的比较    2、FCN上采样理论讲解2.1、双线性插值上采样2.2">
<meta property="og:type" content="article">
<meta property="og:title" content="全卷积网络FCN">
<meta property="og:url" content="https://acodey.github.io/2022/03/31/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CFCN/index.html">
<meta property="og:site_name" content="Acodey">
<meta property="og:description" content="全卷积网络FCN详细讲解（超级详细哦）  1、全卷积网络（FCN）的简单介绍1.1、CNN与FCN的比较    2、FCN上采样理论讲解2.1、双线性插值上采样2.2">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&shareKey=53d190ab6364e8ed3008a3309d8bdb67">
<meta property="article:published_time" content="2022-03-31T08:42:57.000Z">
<meta property="article:modified_time" content="2022-03-31T09:09:59.766Z">
<meta property="article:author" content="acodey">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&shareKey=53d190ab6364e8ed3008a3309d8bdb67"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://acodey.github.io/2022/03/31/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CFCN/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '全卷积网络FCN',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-03-31 17:09:59'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://w.wallhaven.cc/full/wq/wallhaven-wqe1rq.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&amp;shareKey=53d190ab6364e8ed3008a3309d8bdb67')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Acodey</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">全卷积网络FCN</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-31T08:42:57.000Z" title="发表于 2022-03-31 16:42:57">2022-03-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-03-31T09:09:59.766Z" title="更新于 2022-03-31 17:09:59">2022-03-31</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="全卷积网络FCN"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-163de54645.css">
                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p>
<div class="toc">
 <h3><a name="t0"></a>全卷积网络FCN详细讲解（超级详细哦）</h3>
 <ul><li><ul><li><a href="#1FCN_1" target="_self">1、全卷积网络（FCN）的简单介绍</a></li><li><ul><li><a href="#11CNNFCN_2" target="_self">1.1、CNN与FCN的比较</a></li></ul>
   </li><li><a href="#2FCN_10" target="_self">2、FCN上采样理论讲解</a></li><li><ul><li><a href="#21_12" target="_self">2.1、双线性插值上采样</a></li><li><a href="#22_26" target="_self">2.2、反卷积上采样</a></li><li><a href="#23_33" target="_self">2.3、反池化上采样</a></li></ul>
   </li><li><a href="#2_09FCN_38" target="_self">2、 FCN具体实现过程</a></li><li><a href="#3_09FCN_48" target="_self">3、 FCN模型实现过程</a></li><li><ul><li><a href="#31_49" target="_self">3.1、模型训练</a></li><li><a href="#32FCN_102" target="_self">3.2、FCN模型的简单总结</a></li></ul>
  </li></ul>
 </li></ul>
</div>
<p></p> 
<h2><a name="t1"></a><a id="1FCN_1"></a>全卷积网络（FCN）的简单介绍</h2> 
<h3><a name="t2"></a><a id="11CNNFCN_2"></a>1、<a href="https://so.csdn.net/so/search?q=CNN&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=CNN&amp;spm=1001.2101.3001.7020&quot;}" data-tit="CNN" data-pretit="cnn">CNN</a>与FCN的比较</h3> 
<p><strong>CNN:</strong> 在传统的CNN网络中，在最后的卷积层之后会连接上若干个<a href="https://so.csdn.net/so/search?q=%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82&amp;spm=1001.2101.3001.7020&quot;}" data-tit="全连接层" data-pretit="全连接层">全连接层</a>，将卷积层产生的特征图（feature map）映射成为一个固定长度的特征向量。一般的CNN结构适用于图像级别的分类和回归任务，因为它们最后都期望得到输入图像的分类的概率，如ALexNet网络最后输出一个1000维的向量表示输入图像属于每一类的概率。如下图所示：<br> <img src="https://img-blog.csdnimg.cn/20190727205043126.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 在CNN中, 猫的图片输入到AlexNet, 得到一个长为1000的输出向量, 表示输入图像属于每一类的概率, 其中在“tabby cat”这一类统计概率最高, 用来做分类任务。</p> 
<p><strong>FCN:</strong> FCN是对图像进行像素级的分类（也就是每个像素点都进行分类），从而解决了语义级别的图像分割问题。与上面介绍的经典CNN在卷积层使用全连接层得到固定长度的<a href="https://so.csdn.net/so/search?q=%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F&amp;spm=1001.2101.3001.7020&quot;}" data-tit="特征向量" data-pretit="特征向量">特征向量</a>进行分类不同，FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷基层的特征图（feature map）进行上采样，使它恢复到输入图像相同的尺寸，从而可以对每一个像素都产生一个预测，同时保留了原始输入图像中的空间信息，最后奇偶在上采样的特征图进行像素的分类。如下图所示：<br> <img src="https://img-blog.csdnimg.cn/20190727205145371.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 简单的说，FCN与CNN的区别在于FCN把CNN最后的全连接层换成卷积层，其输出的是一张已经标记好的图，而不是一个概率值。</p> 
<h2><a name="t3"></a><a id="2FCN_10"></a>2、FCN上<a href="https://so.csdn.net/so/search?q=%E9%87%87%E6%A0%B7&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E9%87%87%E6%A0%B7&amp;spm=1001.2101.3001.7020&quot;}" data-tit="采样" data-pretit="采样">采样</a>理论讲解</h2> 
<p>FCN网络一般是用来对图像进行语义分割的，于是就需要对图像上的各个像素进行分类，这就需要一个上采样将最后得到的输出上采样到原图的大小。上采样对于低分辨率的特征图，常常采用上采样的方式将它还原高分辨率，这里陈述上采样的三种方法。</p> 
<h3><a name="t4"></a><a id="21_12"></a>2、双线性插值上采样</h3> <h3><a name="t4"></a><a id="21_12"></a>2、双线性插值上采样</h3> 

<p>单线性插值（一个方向上）就是知道两个点的值，并将两点连成一条直线，来确定中间的点的值，假设,现在有两点 <span class="katex--inline"><span class="katex"><span class="katex-mathml">


<p>​       （x_1,y_1 ）、（x_2,y_2）</p>
<p>​<br>​    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord cjk_fallback">（</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord cjk_fallback">）</span><span class="mord cjk_fallback">、</span><span class="mord cjk_fallback">（</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord cjk_fallback">）</span></span></span></span></span>连成一条直线，<span class="katex--inline"><span class="katex"><span class="katex-mathml"></p>
<p>​       [x_1,x_2]</p>
<p>​    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span>中的点就可以用线上的点表示。双线性插值（两个方向上）是一个三维的坐标系，因此，需要找到4个点来确定中心点坐标，如下图所示的例子：<br> <img src="https://img-blog.csdnimg.cn/20190727205304388.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 假如我们想得到未知函数 f 在点 P = (x, y) 的值，假设我们已知函数 f 在 <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"></p>
<p>​        Q_11 = (x_1, y_1)、Q_12 = (x_1, y_2), Q_21 = (x_2, y_1) </p>
<p>​<br>​     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathit">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathit">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span>以及 <span class="katex--inline"><span class="katex"><span class="katex-mathml"></p>
 <div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-163de54645.css">
                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a name="t0"></a><a id="1_0"></a>1、<a href="https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020&quot;}" data-tit="神经网络" data-pretit="神经网络">神经网络</a></h2> 
<p>首先了解神经网络，大家移步这俩篇博客，一篇为纯理论，一篇为实战加理论。</p> 
<ul><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44023658/article/details/105691321">机器学习之神经网络学习及其模型</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44023658/article/details/105694079">入门讲解：使用numpy实现简单的神经网络（BP算法）</a></li></ul> 
<h2><a name="t1"></a><a id="2_6"></a>2、<a href="https://so.csdn.net/so/search?q=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020&quot;}" data-tit="卷积神经网络" data-pretit="卷积神经网络">卷积神经网络</a>之层级结构</h2> 
<p><a target="_blank" rel="noopener" href="http://cs231n.stanford.edu/">cs231n课程</a>里给出了卷积神经网络各个层级结构，如下图<br> <img src="https://img-blog.csdnimg.cn/20200423110238406.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">上图中<a href="https://so.csdn.net/so/search?q=CNN&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=CNN&amp;spm=1001.2101.3001.7020&quot;}" data-tit="CNN" data-pretit="cnn">CNN</a>要做的事情是：给定一张图片，是车还是马未知，是什么车也未知，现在需要模型判断这张图片里具体是一个什么东西，总之输出一个结果：如果是车 那是什么车<br> 所以</p> 
<ul><li>最左边是数据输入层，对数据做一些处理，比如去均值（把输入数据各个维度都中心化为0，避免数据过多偏差，影响训练效果）、归一化（把所有的数据都归一到同样的范围）、PCA/白化等等。CNN只对训练集做“去均值”这一步。<br> 中间是</li><li>CONV：卷积计算层，线性乘积 求和。</li><li>RELU：激励层，上文2.2节中有提到：ReLU是激活函数的一种</li><li>POOL：池化层，简言之，即取区域平均或最大<br> 最右边是</li><li>FC：全连接层</li></ul> 
<p>这几个部分中，卷积计算层是CNN的核心，下文将重点阐述。</p> 
<h2><a name="t2"></a><a id="3CNN_21"></a>3CNN之卷积计算层</h2> 
<p><strong>3.1 CNN怎么进行识别</strong><br> 简言之，当我们给定一个"X"的图案，计算机怎么识别这个图案就是“X”呢？一个可能的办法就是计算机存储一张标准的“X”图案，然后把需要识别的未知图案跟标准"X"图案进行比对，如果二者一致，则判定未知图案即是一个"X"图案。</p> 
<p>而且即便未知图案可能有一些平移或稍稍变形，依然能辨别出它是一个X图案。如此，CNN是把未知图案和标准X图案一个局部一个局部的对比，如下图所示<br> <img src="https://img-blog.csdnimg.cn/20200423111638829.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">而未知图案的局部和标准X图案的局部一个一个比对时的计算过程，便是卷积操作。卷积计算结果为1表示匹配，否则不匹配。</p> 
<p>具体而言，为了确定一幅图像是包含有"X"还是"O"，相当于我们需要判断它是否含有"X"或者"O"，并且假设必须两者选其一，不是"X"就是"O"。<br> <img src="https://img-blog.csdnimg.cn/20200423111727844.png" alt="在这里插入图片描述">理想的情况就像下面这个样子：<br> <img src="https://img-blog.csdnimg.cn/20200423111749574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">标准的"X"和"O"，字母位于图像的正中央，并且比例合适，无变形</p> 
<p>对于计算机来说，只要图像稍稍有一点变化，不是标准的，那么要解决这个问题还是不是那么容易的：<br> <img src="https://img-blog.csdnimg.cn/20200423111817368.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">计算机要解决上面这个问题，一个比较天真的做法就是先保存一张"X"和"O"的标准图像（就像前面给出的例子），然后将其他的新给出的图像来和这两张标准图像进行对比，看看到底和哪一张图更匹配，就判断为哪个字母。</p> 
<p>但是这么做的话，其实是非常不可靠的，因为计算机还是比较死板的。在计算机的“视觉”中，一幅图看起来就像是一个二维的像素数组（可以想象成一个棋盘），每一个位置对应一个数字。在我们这个例子当中，像素值"1"代表白色，像素值"-1"代表黑色。<br> <img src="https://img-blog.csdnimg.cn/20200423111936433.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">当比较两幅图的时候，如果有任何一个像素值不匹配，那么这两幅图就不匹配，至少对于计算机来说是这样的。</p> 
<p>对于这个例子，计算机认为上述两幅图中的白色像素除了中间的3*3的小方格里面是相同的，其他四个角上都不同：<br> <img src="https://img-blog.csdnimg.cn/20200423112352758.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">因此，从表面上看，计算机判别右边那幅图不是"X"，两幅图不同，得出结论：<br> <img src="https://img-blog.csdnimg.cn/20200423112417942.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">但是这么做，显得太不合理了。理想的情况下，我们希望，对于那些仅仅只是做了一些像平移，缩放，旋转，微变形等简单变换的图像，计算机仍然能够识别出图中的"X"和"O"。就像下面这些情况，我们希望计算机依然能够很快并且很准的识别出来：<br> <img src="https://img-blog.csdnimg.cn/20200423112516924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">这也就是CNN出现所要解决的问题。</p> 
<p>Features<br> <img src="https://img-blog.csdnimg.cn/2020042311252932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">对于CNN来说，它是一块一块地来进行比对。它拿来比对的这个“小块”我们称之为Features（特征）。在两幅图中大致相同的位置找到一些粗糙的特征进行匹配，CNN能够更好的看到两幅图的相似性，相比起传统的整幅图逐一比对的方法。</p> 
<p>每一个feature就像是一个小图（就是一个比较小的有值的二维数组）。不同的Feature匹配图像中不同的特征。在字母"X"的例子中，那些由对角线和交叉线组成的features基本上能够识别出大多数"X"所具有的重要特征。<br> <img src="https://img-blog.csdnimg.cn/20200423112648895.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">这些features很有可能就是匹配任何含有字母"X"的图中字母X的四个角和它的中心。那么具体到底是怎么匹配的呢？如下：<br> <img src="https://img-blog.csdnimg.cn/20200423112724201.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423112731294.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423112736875.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423112750538.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423112755586.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">看到这里是不是有了一点头目呢。但其实这只是第一步，你知道了这些Features是怎么在原图上面进行匹配的。但是你还不知道在这里面究竟进行的是怎样的数学计算，比如这个下面3*3的小块到底干了什么？<br> <img src="https://img-blog.csdnimg.cn/20200423112958845.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">这里面的数学操作，就是我们常说的“卷积”操作。接下来，我们来了解下什么是卷积操作。</p> 
<p><strong>3.2 什么是卷积</strong><br> 对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐个元素相乘再求和）的操作就是所谓的『卷积』操作，也是卷积神经网络的名字来源。</p> 
<p>非严格意义上来讲，下图中红框框起来的部分便可以理解为一个滤波器，即带着一组固定权重的神经元。多个滤波器叠加便成了卷积层。<br> <img src="https://img-blog.csdnimg.cn/20200423113727552.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">OK，举个具体的例子。比如下图中，图中左边部分是原始输入数据，图中中间部分是滤波器filter，图中右边是输出的新的二维数据。<br> <img src="https://img-blog.csdnimg.cn/20200423113914152.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">中间滤波器filter与数据窗口做内积，其具体计算过程则是：4<em>0 + 0</em>0 + 0<em>0 + 0</em>0 + 0<em>1 + 0</em>1 + 0<em>0 + 0</em>1 + -4*2 = -8</p> 
<h2><a name="t3"></a><a id="33__58"></a>3.3 图像上的卷积</h2> 
<p>在下图对应的计算过程中，输入是一定区域大小(width*height)的数据，和滤波器filter（带着一组固定权重的神经元）做内积后等到新的二维数据。</p> 
<p>具体来说，左边是图像输入，中间部分就是滤波器filter（带着一组固定权重的神经元），不同的滤波器filter会得到不同的输出数据，比如颜色深浅、轮廓。相当于如果想提取图像的不同特征，则用不同的滤波器filter，提取想要的关于图像的特定信息：颜色深浅或轮廓。</p> 
<p>如下图所示</p> 
<p><img src="https://img-blog.csdnimg.cn/20200423114704894.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><strong>3.4 GIF动态卷积图</strong><br> 在CNN中，滤波器filter（带着一组固定权重的神经元）对局部输入数据进行卷积计算。每计算完一个数据窗口内的局部数据后，数据窗口不断平移滑动，直到计算完所有数据。这个过程中，有这么几个参数：</p> 
<ul><li> <p>a. 深度depth：神经元个数，决定输出的depth厚度。同时代表滤波器个数。</p> </li><li> <p>b. 步长stride：决定滑动多少步可以到边缘。</p> </li><li> <p>c.填充值zero-padding：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总长能被步长整除。</p> </li></ul> 
<p><img src="https://img-blog.csdnimg.cn/20200423115155145.png" alt="在这里插入图片描述">cs231n课程中有一张卷积动图，貌似是用d3js 和一个util 画的，我根据cs231n的卷积动图依次截取了18张图，然后用一gif 制图工具制作了一gif 动态卷积图。如下gif 图所示<br> <img src="https://img-blog.csdnimg.cn/20200423115444476.gif" alt="在这里插入图片描述">可以看到：</p> 
<ul><li> <p>两个神经元，即depth=2，意味着有两个滤波器。</p> </li><li> <p>数据窗口每次移动两个步长取3*3的局部数据，即stride=2。</p> </li><li> <p>zero-padding=1。</p> <p>然后分别以两个滤波器filter为轴滑动数组进行卷积计算，得到两组不同的结果。</p> <p>如果初看上图，可能不一定能立马理解啥意思，但结合上文的内容后，理解这个动图已经不是很困难的事情：</p> </li><li> <p>左边是输入（7<em>7</em>3中，7*7代表图像的像素/长宽，3代表R、G、B 三个颜色通道）</p> </li><li> <p>中间部分是两个不同的滤波器Filter w0、Filter w1</p> </li><li> <p>最右边则是两个不同的输出</p> <p>随着左边数据窗口的平移滑动，滤波器Filter w0 / Filter w1对不同的局部数据进行卷积计算。</p> <p><strong>值得一提的是：</strong></p> </li><li> <p>左边数据在变化，每次滤波器都是针对某一局部的数据窗口进行卷积，这就是所谓的CNN中的局部感知机制。</p> </li><li> <p>打个比方，滤波器就像一双眼睛，人类视角有限，一眼望去，只能看到这世界的局部。如果一眼就看到全世界，你会累死，而且一下子接受全世界所有信息，你大脑接收不过来。当然，即便是看局部，针对局部里的信息人类双眼也是有偏重、偏好的。比如看美女，对脸、胸、腿是重点关注，所以这3个输入的权重相对较大。</p> </li></ul> 
<p>与此同时，数据窗口滑动，导致输入在变化，但中间滤波器Filter w0的权重（即每个神经元连接数据窗口的权重）是固定不变的，这个权重不变即所谓的CNN中的参数（权重）共享机制。</p> 
<ul><li> <p>再打个比方，某人环游全世界，所看到的信息在变，但采集信息的双眼不变。btw，不同人的双眼 看同一个局部信息<br> 所感受到的不同，即一千个读者有一千个哈姆雷特，所以不同的滤波器 就像不同的双眼，不同的人有着不同的反馈结果。</p> </li><li> <p>我第一次看到上面这个动态图的时候，只觉得很炫，另外就是据说计算过程是“相乘后相加”，但到底具体是个怎么相乘后相加的计算过程<br> 则无法一眼看出，网上也没有一目了然的计算过程。本文来细究下。</p> <p>首先，我们来分解下上述动图，如下图<br> <img src="https://img-blog.csdnimg.cn/20200423120125940.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"> 接着，我们细究下上图的具体计算过程。即上图中的输出结果1具体是怎么计算得到的呢？其实，类似wx + b，w对应滤波器Filter w0，x对应不同的数据窗口，b对应Bias b0，相当于滤波器Filter w0与一个个数据窗口相乘再求和后，最后加上Bias b0得到输出结果1，如下过程所示：<br> <img src="https://img-blog.csdnimg.cn/20200423120205232.png" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423120148869.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/20200423120402419.png" alt="在这里插入图片描述"></p> <p><img src="https://img-blog.csdnimg.cn/2020042312041718.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/20200423120426576.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/20200423120508690.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/20200423120515800.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/20200423120524204.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/20200423120619442.png" alt="在这里插入图片描述"><br> 然后滤波器Filter w0固定不变，数据窗口向右移动2步，继续做内积计算，得到0的输出结果<br> <img src="https://img-blog.csdnimg.cn/20200423120640892.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">最后，换做另外一个不同的滤波器Filter w1、不同的偏置Bias b1，再跟图中最左边的数据窗口做卷积，可得到另外一个不同的输出。<br> <img src="https://img-blog.csdnimg.cn/20200423120658434.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> </li></ul> 
<h2><a name="t4"></a><a id="4_CNN_127"></a>4 CNN之激励层，池化层，全连接层</h2> 
<p><strong>4.1 ReLU激励层</strong><br> 第一节俩篇博客介绍了激活函数sigmoid，但实际梯度下降中，sigmoid容易饱和、造成终止梯度传递，且没有0中心化。咋办呢，可以尝试另外一个激活函数：ReLU，其图形表示如下<br> <img src="https://img-blog.csdnimg.cn/20200423120753735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"> 对于输入的负值，输出全为0，对于正值，原样输出。</p> 
<p>下面我们看一下本文的离例子中relu激活函数具体操作：</p> 
<p><img src="https://img-blog.csdnimg.cn/20200423125603934.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423125616543.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423125625871.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 最后，我们将上面所提到的卷积，池化，激活放在一起，就是下面这个样子：<img src="https://img-blog.csdnimg.cn/20200423125645992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">然后，我们加大网络的深度，增加更多的层，就得到深度神经网络了：<br> <img src="https://img-blog.csdnimg.cn/20200423125716828.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>4.2 池化pool层</strong><br> 前头说了，池化，简言之，即取区域平均或最大，如下图所示（图引自cs231n）<br> CNN中使用的另一个有效的工具被称为“池化(Pooling)”。池化可以将一幅大的图像缩小，同时又保留其中的重要信息。池化背后的数学顶多也就是小学二年级水平。它就是将输入图像进行缩小，减少像素信息，只保留重要信息。通常情况下，池化都是2<em>2大小，比如对于max-pooling来说，就是取输入图像中2</em>2大小的块中的最大值，作为结果的像素值，相当于将原始图像缩小了4倍。(注：同理，对于average-pooling来说，就是取2*2大小块的平均值作为结果的像素值。)</p> 
<p><img src="https://img-blog.csdnimg.cn/20200423120848261.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">上图所展示的是取区域最大，即上图左边部分中 左上角2x2的矩阵中6最大，右上角2x2的矩阵中8最大，左下角2x2的矩阵中3最大，右下角2x2的矩阵中4最大，所以得到上图右边部分的结果：6 8 3 4。很简单不是？</p> 
<p><strong>4.3全连接层(Fully connected layers)</strong></p> 
<p><img src="https://img-blog.csdnimg.cn/20200423125809502.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt=" "><img src="https://img-blog.csdnimg.cn/20200423130534936.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423130602879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423130611929.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423130618321.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423130627738.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423130649358.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">根据结果判定为"X"：<br> <img src="https://img-blog.csdnimg.cn/20200423130706477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">在这个过程中，我们定义这一系列操作为”全连接层“(Fully connected layers)：<br> <img src="https://img-blog.csdnimg.cn/20200423130756695.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">全连接层也能够有很多个，如下：<br> <img src="https://img-blog.csdnimg.cn/20200423130809713.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20200423130817178.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">【综合上述所有结构】<br> <img src="https://img-blog.csdnimg.cn/20200423130832695.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
<h2><a name="t5"></a><a id="5__152"></a>5 综合演练</h2> 
<p>参数<br> f:过滤器大小<br> s:步长</p> 
<p><img src="https://img-blog.csdnimg.cn/20200423132256534.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/20200423124806784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyMzY1OA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
<h2><a name="t6"></a><a id="6__160"></a>6 注：</h2> 
<p>本博客参考自：<br> <a target="_blank" rel="noopener" href="https://me.csdn.net/v_JULY_v">v_JULY_v</a><br> <a target="_blank" rel="noopener" href="https://mooc.study.163.com/learn/2001281004?tid=2403023001&amp;_trace_c_p_k2_=6bd177a6a2ee4aabb3292ed9194bbba8#/learn/announce">吴恩达卷积神经网络</a><br> <a target="_blank" rel="noopener" href="https://www.jianshu.com/u/38cd2a8c425e">zhwhong</a></p>
                </div><div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_44023658/article/details/105702098&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-89f5acb30b.css" rel="stylesheet">
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-49037e4d27.css" rel="stylesheet">
        </div>
       Q_22 = (x_2, y_2)


<p>​<br>​    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathit">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathit" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 四个点的值。最常见的情况，f就是一个像素点的像素值。首先在 x 方向进行线性插值，得到：<br> <img src="https://img-blog.csdnimg.cn/20190727205328176.png" alt="在这里插入图片描述"><br> 然后在 y 方向进行线性插值，得到：<br> <img src="https://img-blog.csdnimg.cn/20190727205345741.png" alt="在这里插入图片描述"><br> 综合起来就是双线性插值最后的结果：<br> <img src="https://img-blog.csdnimg.cn/20190727205404112.png" alt="在这里插入图片描述"><br> 由于图像双线性插值只会用相邻的4个点，因此上述公式的分母都是1。<a href="https://so.csdn.net/so/search?q=opencv&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=opencv&amp;spm=1001.2101.3001.7020&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=opencv&amp;spm=1001.2101.3001.7020&quot;}" data-tit="opencv" data-pretit="opencv">opencv</a>中的源码如下，用了一些优化手段，比如用整数计算代替float（下面代码中的*2048就是变11位小数为整数，最后有两个连乘，因此&gt;&gt;22位），以及源图像和目标图像几何中心的对齐</p> </p>
<ul><li>SrcX=(dstX+0.5)* (srcWidth/dstWidth) -0.5</li><li>SrcY=(dstY+0.5) * (srcHeight/dstHeight)-0.5，<br> 这个要重点说一下，源图像和目标图像的原点（0，0）均选择左上角，然后根据插值公式计算目标图像每点像素，假设你需要将一幅5x5的图像缩小成3x3，那么源图像和目标图像各个像素之间的对应关系如下。如果没有这个中心对齐，根据基本公式去算，就会得到左边这样的结果；而用了对齐，就会得到右边的结果：<br> <img src="https://img-blog.csdnimg.cn/20190727205438219.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li></ul> 
<h3><a name="t5"></a><a id="22_26"></a>2.2、反卷积上采样</h3> 
<p><strong>怎样上采样：</strong> 普通的卷积操作，会使得分辨率降低，如下图3<em>3的卷积核去卷积4</em>4得到2*2的输出。<br> <img src="https://img-blog.csdnimg.cn/20190727205525518.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 上采样的过程也是卷积，那么怎么会得到分辨率提高呢？之前我们看卷积时有个保持输出与输入同分辨率的方法就是周围补0。<br> <img src="https://img-blog.csdnimg.cn/20190727205545284.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 其实上面这种补0的方法事有问题的，你想一下，只在四周补0会导致最边上的信息不太好，那我们把这个信息平均下，在每个像素与像素之间补0，如下图所示：<br> <img src="https://img-blog.csdnimg.cn/20190727205607141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
<h3><a name="t6"></a><a id="23_33"></a>2.3、反池化上采样</h3> 
<p>反池化可以用下图来理解，再池化时需要记录下池化的位置，反池化时把池化的位置直接还原，其他位置填0。<br> <img src="https://img-blog.csdnimg.cn/20190727205635411.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 上面三种方法各有优缺，双线性插值方法实现简单，无需训练；反卷积上采样需要训练，但能更好的还原特征图；</p> 
<h2><a name="t7"></a><a id="2    FCN_38"></a>2、 FCN具体实现过程</h2> 
<p>FCN与CNN的核心区别就是FCN将CNN末尾的全连接层转化成了卷积层：以Alexnet为例，输入是227<em>227</em>3的图像，前5层是卷积层，第5层的输出是256个特征图，大小是6<em>6，即256</em>6<em>6，第6、7、8层分别是长度是4096、4096、1000的一维向量。如下图所示：<br> <img src="https://img-blog.csdnimg.cn/20190728153344199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 在FCN中第6、7、8层都是通过卷积得到的，卷积核的大小全部是1 * 1，第6层的输出是4096 * 7 * 7，第7层的输出是4096 * 7 * 7，第8层的输出是1000 * 7 * 7（7是输入图像大小的1/32）,即1000个大小是7</em>7的特征图（称为heatmap），如下图所示：<br> <img src="https://img-blog.csdnimg.cn/20190728153423546.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 经过多次卷积后，图像的分辨率越来越低，为了从低分辨率的热图heatmap恢复到原图大小，以便对原图上每一个像素点进行分类预测，需要对<strong>热图heatmap</strong>进行反卷积，也就是上采样。<strong>论文中首先进行了一个上池化操作，再进行反卷积（上述所提到的上池化操作和反卷积操作，其实可以理解为上卷积操作），使得图像分辨率提高到原图大小</strong>。如下图所示：<br> <img src="https://img-blog.csdnimg.cn/20190728153507888.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>跳级(strip)结构</strong>：对第5层的输出执行32倍的反卷积得到原图，得到的结果不是很精确，论文中同时执行了第4层和第3层输出的反卷积操作（分别需要16倍和8倍的上采样），再把这3个反卷积的结果图像融合，提升了结果的精确度：<br> <img src="https://img-blog.csdnimg.cn/2019072815355086.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 最后像素的分类按照该点在1000张上采样得到的图上的最大的概率来定。FCN可以接受任意大小的输入图像，但是FCN的分类结果还是不够精细，对细节不太敏感，再者没有考虑到像素与像素之间的关联关系，丢失了部分空间信息。</p> 
<h2><a name="t8"></a><a id="3    FCN_48"></a>3、 FCN模型实现过程</h2> 
<h3><a name="t9"></a><a id="31_49"></a>3.1、模型训练</h3> 
<p>• 用AlexNet，VGG16或者GoogleNet训练好的模型做初始化，在这个基础上做fine-tuning，只需在末尾加上upsampling，参数的学习还是利用CNN本身的反向传播原理。</p> 
<p>• 采用全图做训练，不进行局部抽样。实验证明直接用全图已经很高效。<br> FCN例子: 输入可为任意尺寸图像彩色图像；输出与输入尺寸相同，深度为：20类目标+背景=21，模型基于AlexNet。</p> 
<p>• 蓝色：卷积层。</p> 
<p>• 绿色：Max Pooling层。</p> 
<p>• 黄色: 求和运算, 使用逐数据相加，把三个不同深度的预测结果进行融合：较浅的结果更为精细，较深的结果更为鲁棒。</p> 
<p>• 灰色: 裁剪, 在融合之前，使用裁剪层统一两者大小, 最后裁剪成和输入相同尺寸输出。</p> 
<p>• 对于不同尺寸的输入图像，各层数据的尺寸（height，width）相应变化，深度（channel）不变。<br> <img src="https://img-blog.csdnimg.cn/2019072816051843.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> • 全卷积层部分进行特征提取, 提取卷积层（3个蓝色层）的输出来作为预测21个类别的特征。</p> 
<p>• 图中虚线内是反卷积层的运算, 反卷积层（3个橙色层）可以把输入数据尺寸放大。和卷积层一样，升采样的具体参数经过训练确定。</p> 
<p><strong>1、 以经典的AlexNet分类网络为初始化。最后两级是全连接（红色），参数弃去不用。</strong><br> <img src="https://img-blog.csdnimg.cn/20190728160503480.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>2、 反卷积（橙色）的步长为32，这个网络称为FCN-32s</strong></p> 
<p>从特征小图（）预测分割小图（），之后直接升采样为大图。<br> <img src="https://img-blog.csdnimg.cn/20190728153852609.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>3、 第二次反卷积步长为16，这个网络称为FCN-16s</strong></p> 
<p>升采样分为两次完成（橙色×2）, 在第二次升采样前，把第4个pooling层（绿色）的预测结果（蓝色）融合进来。使用跳级结构提升精确性。<br> <img src="https://img-blog.csdnimg.cn/2019072815394485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>4、 第三次反卷积步长为8，记为FCN-8s。</strong></p> 
<p>升采样分为三次完成（橙色×3）, 进一步融合了第3个pooling层的预测结果。<br> <img src="https://img-blog.csdnimg.cn/20190728154021573.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 其他参数:<br> • minibatch：20张图片<br> • learning rate：0.001<br> • 初始化：分类网络之外的卷积层参数初始化为0<br> • 反卷积参数初始化为bilinear插值。最后一层反卷积固定位bilinear插值不做学习<br> <img src="https://img-blog.csdnimg.cn/20190728154055287.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <strong>总体来说，本文的逻辑如下：</strong></p> 
<p>• 想要精确预测每个像素的分割结果<br> • 必须经历从大到小，再从小到大的两个过程<br> • 在升采样过程中，分阶段增大比一步到位效果更好<br> • 在升采样的每个阶段，使用降采样对应层的特征进行辅助</p> 
<p><strong>缺点:</strong></p> 
<ol><li>得到的结果还是不够精细。进行8倍上采样虽然比32倍的效果好了很多，但是上采样的结果还是比较模糊和平滑，对图像中的细节不敏感</li><li>对各个像素进行分类，没有充分考虑像素与像素之间的关系。忽略了在通常的基于像素分类的分割方法中使用的空间规整（spatial regularization）步骤，缺乏空间一致性</li></ol> 
<h3><a name="t10"></a><a id="32FCN_102"></a>3.2、FCN模型的简单总结</h3> 
<p>FCN的卷积网络部分可以采用VGG、GoogleNet、AlexNet等作为前置基础网络，在这些的预训练基础上进行迁移学习与finetuning，对反卷积的结果跟对应的正向feature map进行叠加输出(这样做的目的是得到更加准确的像素级别分割)，根据上采样的倍数不一样分为FCN-8S、FCN-16S、FCN-32S，图示如下：</p> 
<p><strong>详情：</strong></p> 
<p>对原图像进行卷积 conv1、pool1后原图像缩小为1/2；</p> 
<p>之后对图像进行第二次 conv2、pool2后图像缩小为1/4；</p> 
<p>继续对图像进行第三次卷积操作conv3、pool3缩小为原图像的1/8，此时保留pool3的featureMap；</p> 
<p>继续对图像进行第四次卷积操作conv4、pool4，缩小为原图像的1/16，保留pool4的featureMap；</p> 
<p>最后对图像进行第五次卷积操作conv5、pool5，缩小为原图像的1/32，</p> 
<p>然后把原来CNN操作中的全连接变成卷积操作conv6、conv7，图像的featureMap数量改变但是图像大小依然为原图的1/32，此时图像不再叫featureMap而是叫heatMap。</p> 
<p><strong>实例</strong></p> 
<p>现在我们有1/32尺寸的heatMap，1/16尺寸的featureMap和1/8尺寸的featureMap，1/32尺寸的heatMap进行upsampling操作之后，因为这样的操作还原的图片仅仅是conv5中的<a href="https://so.csdn.net/so/search?q=%E5%8D%B7%E7%A7%AF%E6%A0%B8&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E5%8D%B7%E7%A7%AF%E6%A0%B8&amp;spm=1001.2101.3001.7020&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E5%8D%B7%E7%A7%AF%E6%A0%B8&amp;spm=1001.2101.3001.7020&quot;}" data-tit="卷积核" data-pretit="卷积核">卷积核</a>中的特征，限于精度问题不能够很好地还原图像当中的特征，因此在这里向前迭代。把conv4中的卷积核对上一次upsampling之后的图进行反卷积补充细节（相当于一个差值过程），最后把conv3中的卷积核对刚才upsampling之后的图像进行再次反卷积补充细节，最后就完成了整个图像的还原。（具体怎么做，本博客已经在3.1节进行了详细的讲解，不懂的地方可以回过头不查看。）如下图所示：注，上下两个图表达相同的意思。<br> <img src="https://img-blog.csdnimg.cn/20190728171536973.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
                </div><div><div></div></div>
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-89f5acb30b.css" rel="stylesheet">
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-49037e4d27.css" rel="stylesheet">
        </div>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">acodey</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://acodey.github.io/2022/03/31/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CFCN/">https://acodey.github.io/2022/03/31/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CFCN/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://acodey.github.io" target="_blank">Acodey</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&amp;shareKey=53d190ab6364e8ed3008a3309d8bdb67" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/03/31/CNN%E8%AF%A6%E8%A7%A3/"><img class="prev-cover" src="https://note.youdao.com/yws/api/personal/file/WEBa91ac9f73616f8a525d36fb7861278e9?method=getImage&amp;version=79&amp;cstk=c8MhR8Y_" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">CNN详解</div></div></a></div><div class="next-post pull-right"><a href="/2022/03/31/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2-DTC/"><img class="next-cover" src="https://note.youdao.com/yws/api/personal/file/WEBa91ac9f73616f8a525d36fb7861278e9?method=getImage&amp;version=79&amp;cstk=c8MhR8Y_" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">图像分割-DTC</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://w.wallhaven.cc/full/wq/wallhaven-wqe1rq.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">acodey</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">真不吃香菜</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#content_views"><span class="toc-number">1.</span> <span class="toc-text">全卷积网络FCN详细讲解（超级详细哦）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">全卷积网络（FCN）的简单介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#content_views"><span class="toc-number">1.</span> <span class="toc-text">1、CNN与FCN的比较</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">2、FCN上采样理论讲解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#content_views"><span class="toc-number">1.</span> <span class="toc-text">2、双线性插值上采样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#content_views"><span class="toc-number">2.</span> <span class="toc-text">2、双线性插值上采样</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">1、神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">2、卷积神经网络之层级结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">3CNN之卷积计算层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">3.3 图像上的卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">4 CNN之激励层，池化层，全连接层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">5 综合演练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">6 注：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#content_views"><span class="toc-number">1.</span> <span class="toc-text">2.2、反卷积上采样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#content_views"><span class="toc-number">2.</span> <span class="toc-text">2.3、反池化上采样</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">2、 FCN具体实现过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#content_views"><span class="toc-number"></span> <span class="toc-text">3、 FCN模型实现过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#content_views"><span class="toc-number">1.</span> <span class="toc-text">3.1、模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#content_views"><span class="toc-number">2.</span> <span class="toc-text">3.2、FCN模型的简单总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/03/31/CNN%E8%AF%A6%E8%A7%A3/" title="CNN详解"><img src="https://note.youdao.com/yws/api/personal/file/WEBa91ac9f73616f8a525d36fb7861278e9?method=getImage&amp;version=79&amp;cstk=c8MhR8Y_" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN详解"/></a><div class="content"><a class="title" href="/2022/03/31/CNN%E8%AF%A6%E8%A7%A3/" title="CNN详解">CNN详解</a><time datetime="2022-03-31T08:59:57.000Z" title="发表于 2022-03-31 16:59:57">2022-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/31/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CFCN/" title="全卷积网络FCN"><img src="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&amp;shareKey=53d190ab6364e8ed3008a3309d8bdb67" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全卷积网络FCN"/></a><div class="content"><a class="title" href="/2022/03/31/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CFCN/" title="全卷积网络FCN">全卷积网络FCN</a><time datetime="2022-03-31T08:42:57.000Z" title="发表于 2022-03-31 16:42:57">2022-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/31/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2-DTC/" title="图像分割-DTC"><img src="https://note.youdao.com/yws/api/personal/file/WEBa91ac9f73616f8a525d36fb7861278e9?method=getImage&amp;version=79&amp;cstk=c8MhR8Y_" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图像分割-DTC"/></a><div class="content"><a class="title" href="/2022/03/31/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2-DTC/" title="图像分割-DTC">图像分割-DTC</a><time datetime="2022-03-31T08:14:45.000Z" title="发表于 2022-03-31 16:14:45">2022-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="机器学习"><img src="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&amp;shareKey=53d190ab6364e8ed3008a3309d8bdb67" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="机器学习"/></a><div class="content"><a class="title" href="/2022/01/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="机器学习">机器学习</a><time datetime="2022-01-12T16:23:28.000Z" title="发表于 2022-01-13 00:23:28">2022-01-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/12/this-is-a-test/" title="this is a test"><img src="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&amp;shareKey=53d190ab6364e8ed3008a3309d8bdb67" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="this is a test"/></a><div class="content"><a class="title" href="/2022/01/12/this-is-a-test/" title="this is a test">this is a test</a><time datetime="2022-01-12T15:51:45.000Z" title="发表于 2022-01-12 23:51:45">2022-01-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By acodey</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Cause that's what I said I would do from the start.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>