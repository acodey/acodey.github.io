<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>机器学习 | Acodey</title><meta name="author" content="acodey"><meta name="copyright" content="acodey"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="矩阵分解与预测推荐系统之矩阵分解有一缺少部分元素的矩阵R，现通过将其分解为P,Q两个子矩阵，预测 “-“的可能值，R的行数为i，列数为j    5 3 - 1    4 - - 1   1 1 - 5   1 - - 4   - 1 5 4   构建损失函数损失函数：实际R（i，j）与测得的R‘（i，j）各个元素的误差平方和   不过为了防止过拟合，需要添加正则化项  过拟合：给定一个假设空间H，">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习">
<meta property="og:url" content="https://acodey.github.io/2022/01/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Acodey">
<meta property="og:description" content="矩阵分解与预测推荐系统之矩阵分解有一缺少部分元素的矩阵R，现通过将其分解为P,Q两个子矩阵，预测 “-“的可能值，R的行数为i，列数为j    5 3 - 1    4 - - 1   1 1 - 5   1 - - 4   - 1 5 4   构建损失函数损失函数：实际R（i，j）与测得的R‘（i，j）各个元素的误差平方和   不过为了防止过拟合，需要添加正则化项  过拟合：给定一个假设空间H，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&shareKey=53d190ab6364e8ed3008a3309d8bdb67">
<meta property="article:published_time" content="2022-01-12T16:23:28.000Z">
<meta property="article:modified_time" content="2022-02-21T08:46:49.171Z">
<meta property="article:author" content="acodey">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&shareKey=53d190ab6364e8ed3008a3309d8bdb67"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://acodey.github.io/2022/01/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-21 16:46:49'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://w.wallhaven.cc/full/wq/wallhaven-wqe1rq.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&amp;shareKey=53d190ab6364e8ed3008a3309d8bdb67')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Acodey</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-01-12T16:23:28.000Z" title="发表于 2022-01-13 00:23:28">2022-01-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-21T08:46:49.171Z" title="更新于 2022-02-21 16:46:49">2022-02-21</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="矩阵分解与预测"><a href="#矩阵分解与预测" class="headerlink" title="矩阵分解与预测"></a>矩阵分解与预测</h1><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/shenxiaolin/p/8637794.html"><u>推荐系统之矩阵分解</u></a><br>有一缺少部分元素的矩阵R，现通过将其分解为P,Q两个子矩阵，预测 “-“的可能值，R的行数为i，列数为j</p>
<table>
<thead>
<tr>
<th align="center">5</th>
<th align="center">3</th>
<th align="center">-</th>
<th align="center">1</th>
</tr>
</thead>
<tbody><tr>
<td align="center">4</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">-</td>
<td align="center">5</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">4</td>
</tr>
<tr>
<td align="center">-</td>
<td align="center">1</td>
<td align="center">5</td>
<td align="center">4</td>
</tr>
</tbody></table>
<h2 id="构建损失函数"><a href="#构建损失函数" class="headerlink" title="构建损失函数"></a>构建损失函数</h2><p>损失函数：实际R（i，j）与测得的R‘（i，j）各个元素的误差平方和</p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB7f561a6adddfb989eb678a49e79d334b?method=download&shareKey=fd3f879a4f1a05d125c14ba94caa0e0e"></p>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB7db2ba17656a6ab351769d64f070b48d?method=download&shareKey=d5cf258aeb82181ec4e0978560989afb"></p>
<p>不过为了防止过拟合，需要添加正则化项</p>
<ul>
<li>过拟合：给定一个假设空间H，一个假设h属于H，如果存在其他的假设h’属于H,使得在训练样例上h的错误率比h’小，但在整个实例分布上h’比h的错误率小，那么就说假设h过度拟合训练数据。<br><img src="https://note.youdao.com/yws/api/personal/file/WEB04f2156c935d72e3d0fd3847bacb91a3?method=download&shareKey=4fefeba84fe912c61965ef009f13c1de"></li>
</ul>
<h2 id="通过梯度下降法获得修正的p和q分量"><a href="#通过梯度下降法获得修正的p和q分量" class="headerlink" title="通过梯度下降法获得修正的p和q分量"></a>通过梯度下降法获得修正的p和q分量</h2><ul>
<li>求解损失函数的负梯度：</li>
</ul>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB3cdbb5f6dcf94d07189599cc6cd4a133?method=download&shareKey=0053802f10ff711aefb916d627980bc8"></p>
<ul>
<li>根据负梯度的方向更新变量：<br><img src="https://note.youdao.com/yws/api/personal/file/WEB4da403cca94d05741b4a79b9afe832fb?method=download&shareKey=13e679f7e23c5d48ddfab90cb54b0cae"></li>
</ul>
<h2 id="迭代算法求得R’及绘制收敛曲线图"><a href="#迭代算法求得R’及绘制收敛曲线图" class="headerlink" title="迭代算法求得R’及绘制收敛曲线图"></a>迭代算法求得R’及绘制收敛曲线图</h2><p>预测矩阵<br><img src="https://note.youdao.com/yws/api/personal/file/WEB0d0c32792dc66475cfa279a9f3a9b10c?method=download&shareKey=f009f4348cbafd20c53ccbf6d9fdee1a"><br>损失函数的收敛曲线图<br><img src="https://note.youdao.com/yws/api/personal/file/WEB625ebd676ab1c41d9d61c2dd4293e2fa?method=download&shareKey=f97a42be52282090df06ee1d4fdf4b3a"></p>
<h2 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradAscent</span>(<span class="params">data, K</span>):</span>  <span class="comment"># 传入原始数据</span></span><br><span class="line">    data_mat = mat(data)</span><br><span class="line">    m, n = shape(data_mat)  <span class="comment"># 获取行,列数</span></span><br><span class="line">    p = mat(random.random((m, K)))  <span class="comment"># 随机生成两个子矩阵</span></span><br><span class="line">    q = mat(random.random((K, n)))</span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line">    α = <span class="number">0.0002</span></span><br><span class="line">    β = <span class="number">0.02</span></span><br><span class="line">    times = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">for</span> time <span class="keyword">in</span> <span class="built_in">range</span>(times):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                e = data_mat[i, j]</span><br><span class="line">                <span class="keyword">if</span> data_mat[i, j] &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">                        e = e - p[i, k] * q[k, j]  <span class="comment"># 子矩阵乘积的[i,j]位数值</span></span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(K):  <span class="comment"># p&#x27;[i,k] = p[i,k]+α(2e[i,j]q[k,j]−β*p[i,k])</span></span><br><span class="line">                        p[i, k] = p[i, k] + α * (<span class="number">2</span> * e * q[k, j] - β * p[i, k])</span><br><span class="line">                        q[k, j] = q[k, j] + α * (<span class="number">2</span> * e * p[i, k] - β * q[k, j])</span><br><span class="line">        loss = <span class="number">0.0</span>  <span class="comment"># 损失值</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> data_mat[i, j] &gt; <span class="number">0</span>:</span><br><span class="line">                    e = <span class="number">0.0</span></span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">                        e = e + p[i, k] * q[k, j]  <span class="comment"># 算得测试值</span></span><br><span class="line">                    loss = (data_mat[i, j] - e) * (data_mat[i, j] - e)</span><br><span class="line">                    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(K):  <span class="comment"># 为了能够有较好的泛化能力，会在损失函数中加入正则项β/2 ∑(k=1,K)(p^2[i,k]+q^2[k,j])</span></span><br><span class="line">                        loss = loss + β * (p[i, k] * p[i, k] + q[k, j] * q[k, j]) / <span class="number">2</span></span><br><span class="line">        result.append(loss)</span><br><span class="line">        <span class="keyword">if</span> loss &lt; <span class="number">0.01</span>: <span class="keyword">break</span>  <span class="comment"># 当损失值小于此数时,结束循环</span></span><br><span class="line">        <span class="keyword">if</span> time % <span class="number">2000</span> == <span class="number">0</span>: <span class="built_in">print</span>(loss)  <span class="comment"># 每隔2000次输出一次损失值大小</span></span><br><span class="line">    <span class="keyword">return</span> p, q, result  <span class="comment"># 返回求得的子矩阵</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">DATA = [[<span class="number">5</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">5</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">4</span>]]</span><br><span class="line">P, Q, result = gradAscent(DATA, <span class="number">5</span>)</span><br><span class="line">n = <span class="built_in">len</span>(result)</span><br><span class="line">x = <span class="built_in">range</span>(n)</span><br><span class="line">plt.plot(x, result, <span class="string">&#x27;r-&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(P * Q)</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="逻辑回归及鸢尾花分类"><a href="#逻辑回归及鸢尾花分类" class="headerlink" title="逻辑回归及鸢尾花分类"></a>逻辑回归及鸢尾花分类</h1><h2 id="手工推导逻辑回归梯度下降实现"><a href="#手工推导逻辑回归梯度下降实现" class="headerlink" title="手工推导逻辑回归梯度下降实现"></a>手工推导逻辑回归梯度下降实现</h2><p><img src="https://note.youdao.com/yws/api/personal/file/WEB14634763005f75cb07ef47bf1bad6974?method=download&shareKey=2458f81f93d639681faa2616762f0727">  </p>
<ul>
<li><h3 id="第二种推导过程"><a href="#第二种推导过程" class="headerlink" title="第二种推导过程"></a>第二种推导过程</h3></li>
</ul>
<p> <img src="https://note.youdao.com/yws/api/personal/file/WEB04bdb47208a608037b5c29bc7a0a688a?method=download&shareKey=8367774a89a331493247ec8ccee1f042" style="zoom:50%">  还可以写成<br> <img src="https://note.youdao.com/yws/api/personal/file/WEBa04752e66ae211b96949a7e2d6203963?method=download&shareKey=e6c10b13af462b7b90aa9c8cdf49d553" style="zoom:60%">  </p>
<p>取似然函数:<br><img src="https://note.youdao.com/yws/api/personal/file/WEB5b3688fdacef45799caee2dca41d2e8c?method=download&shareKey=218b0654e967bd0cf481cc637e08776e" style="zoom:50%">  </p>
<p>对数似然函数为：<img src="https://note.youdao.com/yws/api/personal/file/WEBcd195a37309f7034e12601f00e92da78?method=download&shareKey=1a96ec7264389f5141be3dd6b5c048db" style="zoom:50%"><br>最大似然估计就是求l(θ)使取最大值时的θ，其实这里可以使用梯度上升法求解，求得的θ就是要求的最佳参数。但是，在这里将J(θ)取为下式，即：<br> <img src="https://note.youdao.com/yws/api/personal/file/WEB69c7e18a0a7b6b29533fb86d3c35808c?method=download&shareKey=8afbe49576b3ef74231f61782a2b5311" style="zoom:45%"><br>因为乘了一个负的系数-1/m，所以取J(θ)最小值时的θ为要求的最佳参数。<br>θ的更新过程（梯度下降）：  </p>
<img src="https://note.youdao.com/yws/api/personal/file/WEB49df5f69b9f4777fcadd5eefa1f58706?method=download&shareKey=0e9b68d45c5aba314784acb2bb9c4abb" style="zoom:45%">  
<img src="https://note.youdao.com/yws/api/personal/file/WEB35fff56ef30f9c1dab3544dd182f3d39?method=download&shareKey=35733c64bcd386b468ec2062e044d7c9">

<h2 id="用逻辑回归实现鸢尾花分类"><a href="#用逻辑回归实现鸢尾花分类" class="headerlink" title="用逻辑回归实现鸢尾花分类"></a>用逻辑回归实现鸢尾花分类</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line">iris = load_iris()</span><br><span class="line"><span class="comment"># 取一部分用作训练集</span></span><br><span class="line">indexs = random.sample(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">50</span>), <span class="number">30</span>) + random.sample(<span class="built_in">range</span>(<span class="number">50</span>, <span class="number">100</span>), <span class="number">30</span>) + random.sample(<span class="built_in">range</span>(<span class="number">100</span>, <span class="number">150</span>), <span class="number">30</span>)</span><br><span class="line">X = []</span><br><span class="line">y = []</span><br><span class="line">lr = LinearRegression()</span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">    X.append(iris.data[index])</span><br><span class="line">    y.append(iris.target[index])</span><br><span class="line"></span><br><span class="line">lr.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(lr.coef_, <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">coef = lr.coef_  <span class="comment"># 预测得出的系数</span></span><br><span class="line"></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">150</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;NO:&quot;</span>,i+<span class="number">1</span>)</span><br><span class="line">    y = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        y += iris.data[i][j] * coef[j]</span><br><span class="line">    <span class="built_in">print</span>(y, <span class="string">&#x27; &#x27;</span>, iris.target[i])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">round</span>(y) == iris.target[i]:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;预测正确&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;预测错误&quot;</span>)</span><br><span class="line">rate = count/<span class="number">150</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;正确率为：&quot;</span>,rate)</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(iris.data,iris.target,test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)</span><br><span class="line">logisticregression = linear_model.LogisticRegression(penalty=<span class="string">&#x27;l2&#x27;</span>, C=<span class="number">1.0</span>)</span><br><span class="line">model = logisticregression.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(model.coef_, <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">y_predict = model.predict(X_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;模型得分&#x27;</span>, <span class="string">&#x27;\n&#x27;</span>, model.score(X_test, y_test))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h2><img src="https://note.youdao.com/yws/api/personal/file/WEBd875aaa1d7117ce9b233baccb75e64fe?method=download&shareKey=a08badb8d032093d3ae290c43781ee4f" style="zoom:80%">  

<h1 id="一元线性回归与梯度下降"><a href="#一元线性回归与梯度下降" class="headerlink" title="一元线性回归与梯度下降"></a>一元线性回归与梯度下降</h1><h2 id="手工推导"><a href="#手工推导" class="headerlink" title="手工推导"></a>手工推导</h2><img src="https://note.youdao.com/yws/api/personal/file/WEB6fc899795be6f08ec56ae9fb57881cee?method=download&shareKey=88bec6c72ed9f0c7c74d0eb16b6df0a5" style="zoom:45%">  

<ul>
<li><h3 id="这里注意在处理数据时，数据不宜过大"><a href="#这里注意在处理数据时，数据不宜过大" class="headerlink" title="这里注意在处理数据时，数据不宜过大"></a>这里注意在处理数据时，数据不宜过大</h3></li>
</ul>
<h2 id="作业的代码实现"><a href="#作业的代码实现" class="headerlink" title="作业的代码实现"></a>作业的代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#房屋价格与面积的一元线性回归</span></span><br><span class="line">x = [<span class="number">1.50</span>, <span class="number">2.00</span>, <span class="number">2.50</span>, <span class="number">3.00</span>, <span class="number">3.50</span>, <span class="number">4.00</span>, <span class="number">6.00</span>]</span><br><span class="line">y = [<span class="number">64.50</span>, <span class="number">74.50</span>, <span class="number">84.50</span>, <span class="number">94.50</span>, <span class="number">114.50</span>, <span class="number">154.50</span>, <span class="number">184.50</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#设回归函数为 y = kx+b</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dk</span>(<span class="params">k,b</span>):</span></span><br><span class="line">    m = <span class="built_in">len</span>(x)</span><br><span class="line">    s = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        s += (x[i]*k +b - y[i])*x[i]</span><br><span class="line">    <span class="keyword">return</span> s/m</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">db</span>(<span class="params">k,b</span>):</span></span><br><span class="line">    m = <span class="built_in">len</span>(x)</span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        n = n + x[i]*k +b - y[i]</span><br><span class="line">    <span class="keyword">return</span> n/m</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span>():</span></span><br><span class="line">    a = <span class="number">0.1</span></span><br><span class="line">    k = <span class="number">0.1</span></span><br><span class="line">    b = <span class="number">0.1</span></span><br><span class="line">    m=<span class="built_in">len</span>(x)</span><br><span class="line">    time = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span>(time!=<span class="number">10000</span>):</span><br><span class="line"></span><br><span class="line">        b = b -a*db(k,b)</span><br><span class="line">        k = k -a*dk(k,b)</span><br><span class="line">        loss = <span class="number">0</span></span><br><span class="line">        <span class="built_in">print</span>(k,b)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x)):</span><br><span class="line">            loss = loss + (k*x[i] + b - y[i])**<span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> loss &lt; <span class="number">1000</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        time = time+<span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="KNN分类算法及测试鸢尾花数据集"><a href="#KNN分类算法及测试鸢尾花数据集" class="headerlink" title="KNN分类算法及测试鸢尾花数据集"></a>KNN分类算法及测试鸢尾花数据集</h1><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/27825dc77a1a"><u>原理详解</u></a>  </p>
<h2 id="算法步骤"><a href="#算法步骤" class="headerlink" title="算法步骤"></a>算法步骤</h2><ul>
<li><h3 id="1-分割数据集"><a href="#1-分割数据集" class="headerlink" title="1.分割数据集"></a>1.分割数据集</h3>将数据一部分划分为实验数据，用来预测测试数据和模型准确性</li>
<li><h3 id="2-计算测试集中的每一个元素到训练集所有元素中最近的p个元素"><a href="#2-计算测试集中的每一个元素到训练集所有元素中最近的p个元素" class="headerlink" title="2.计算测试集中的每一个元素到训练集所有元素中最近的p个元素"></a>2.计算测试集中的每一个元素到训练集所有元素中最近的p个元素</h3>这里使用欧氏距离计算：<img src="https://note.youdao.com/yws/api/personal/file/WEBd3c0419785e78ab61062bb9d631cbbcb?method=download&shareKey=62dcb528aa5f0b51c5ff20eb4742693d" style="zoom:60%"> </li>
</ul>
<ul>
<li><h3 id="3-将这p个元素的类别的数量进行排序，数量最多的设定为测试集的元素的类别"><a href="#3-将这p个元素的类别的数量进行排序，数量最多的设定为测试集的元素的类别" class="headerlink" title="3.将这p个元素的类别的数量进行排序，数量最多的设定为测试集的元素的类别"></a>3.将这p个元素的类别的数量进行排序，数量最多的设定为测试集的元素的类别</h3></li>
<li><h3 id="4-循环，预测测试集的所有元素"><a href="#4-循环，预测测试集的所有元素" class="headerlink" title="4.循环，预测测试集的所有元素"></a>4.循环，预测测试集的所有元素</h3></li>
</ul>
<h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># KNN的思想：k=3，看实线圆圈，红色三角形占比2/3，故将绿色圆分给红色三角形；K=5，看虚线圆圈，蓝色正方形占比3/5，故将绿色圆分给蓝色正方形。即如果一个样本在特征空间中的k</span></span><br><span class="line"><span class="comment"># 个最相邻的样本中，大多数属于某一个类别，则该样本也属于这个类别 链接：https://www.jianshu.com/p/27825dc77a1a</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> neighbors</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取KNN分类器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">knn = neighbors.KNeighborsClassifier()</span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line"><span class="built_in">print</span>(iris)</span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line">knn.fit(iris.data, iris.target)</span><br><span class="line"><span class="comment"># 输入预测模型进行预测</span></span><br><span class="line">predictedLabel = knn.predict([[<span class="number">5.9</span>, <span class="number">3.</span>, <span class="number">5.1</span>, <span class="number">1.8</span>]])</span><br><span class="line"><span class="comment"># 输出预测结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(predictedLabel)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.分割数据集</span></span><br><span class="line"><span class="comment"># 2.计算测试集中的每一个元素到训练集所有元素中最近的p个元素</span></span><br><span class="line"><span class="comment"># 3.将这p个元素的类别的数量进行排序，数量最多的设定为测试集的元素的类别</span></span><br><span class="line"><span class="comment"># 4.循环，预测测试集的所有元素</span></span><br><span class="line"><span class="comment"># 5.计算测试集的准确率</span></span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="comment"># 1.分割数据集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=<span class="number">0.7</span>)</span><br><span class="line"><span class="comment"># print(X)</span></span><br><span class="line">y_predict = []</span><br><span class="line">p = <span class="number">3</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_test)):</span><br><span class="line">    Xtes = X_test[i]</span><br><span class="line">    Dis = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_train)):</span><br><span class="line">        Xtra = X_train[j]</span><br><span class="line">        ytra = y_train[j]</span><br><span class="line">        dis = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Xtes)):</span><br><span class="line">            dis += <span class="built_in">pow</span>((Xtes[k] - Xtra[k]), <span class="number">2</span>)</span><br><span class="line">        Dis[math.sqrt(dis)] = ytra</span><br><span class="line">    <span class="comment"># print(Dis)</span></span><br><span class="line">    <span class="comment"># print(len(Dis))</span></span><br><span class="line">    sortedNotes = <span class="built_in">sorted</span>(Dis.items(), key=operator.itemgetter(<span class="number">0</span>), reverse=<span class="literal">False</span>)</span><br><span class="line">    W = []</span><br><span class="line">    <span class="comment"># 2.计算测试集中的每一个元素到训练集所有元素中最近的p个元素</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(p):</span><br><span class="line">        s = <span class="built_in">list</span>(sortedNotes[t])</span><br><span class="line">        W.append(s[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 3.将这p个元素的类别的数量进行排序，数量最多的设定为测试集的元素的类别</span></span><br><span class="line">    most = <span class="built_in">max</span>(W, key=W.count)</span><br><span class="line">    y_predict.append(most)</span><br><span class="line"><span class="comment"># 5.计算测试集的准确率</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_test)):</span><br><span class="line">    <span class="keyword">if</span> y_test[i] == y_predict[i]:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;手写测试准确值:&#x27;</span>, count / <span class="built_in">len</span>(y_test))</span><br><span class="line">plt.plot(y_test, <span class="string">&#x27;r-&#x27;</span>)</span><br><span class="line">plt.plot(y_predict, <span class="string">&#x27;b-&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<h1 id="K-means聚类算法及测试鸢尾花数据集"><a href="#K-means聚类算法及测试鸢尾花数据集" class="headerlink" title="K-means聚类算法及测试鸢尾花数据集"></a>K-means聚类算法及测试鸢尾花数据集</h1><h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><ul>
<li><h3 id="生成k个中心质点（及k个簇）"><a href="#生成k个中心质点（及k个簇）" class="headerlink" title="生成k个中心质点（及k个簇）"></a>生成k个中心质点（及k个簇）</h3></li>
<li><h3 id="样本分配："><a href="#样本分配：" class="headerlink" title="样本分配："></a>样本分配：</h3><p>  利用欧氏距离：</p>
<img src="https://note.youdao.com/yws/api/personal/file/WEBd3c0419785e78ab61062bb9d631cbbcb?method=download&shareKey=62dcb528aa5f0b51c5ff20eb4742693d" style="zoom:60%">  
计算与各个中心质点的距离，并与加入距离最近的质点所代表簇  </li>
<li><h3 id="更新各个簇的中心质点"><a href="#更新各个簇的中心质点" class="headerlink" title="更新各个簇的中心质点"></a>更新各个簇的中心质点</h3><p>  具体操作为：将属于同一种簇的数据，通过求取平均值的方法，重新计算中心质点</p>
</li>
<li><h3 id="循环第二步和第三步"><a href="#循环第二步和第三步" class="headerlink" title="循环第二步和第三步"></a>循环第二步和第三步</h3></li>
<li><h3 id="当中心质点没有更新或者打到约束次数后，停止循环"><a href="#当中心质点没有更新或者打到约束次数后，停止循环" class="headerlink" title="当中心质点没有更新或者打到约束次数后，停止循环"></a>当中心质点没有更新或者打到约束次数后，停止循环</h3></li>
</ul>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># k-means算法分类鸢尾花数据集</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data[:, :<span class="number">2</span>]  <span class="comment"># 表示我们取特征空间中的2个维度</span></span><br><span class="line">y = iris[<span class="string">&#x27;target&#x27;</span>]  <span class="comment"># 实际类别</span></span><br><span class="line"><span class="comment"># 绘制数据分布图</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span></span><br><span class="line">n = shape(X)[<span class="number">1</span>]</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=<span class="string">&quot;red&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;数据预览&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sepal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;sepal width&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据向量计算欧式距离</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span>(<span class="params">vecA, vecB</span>):</span></span><br><span class="line">    <span class="keyword">return</span> sqrt(<span class="built_in">sum</span>(power(vecA - vecB, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_kmeans</span>(<span class="params">X, k</span>):</span>  <span class="comment"># X是测试集 k是分类的种类数目</span></span><br><span class="line"></span><br><span class="line">    n = shape(X)[<span class="number">1</span>]  <span class="comment"># 获取列数</span></span><br><span class="line">    centr = mat(zeros((k, n)))  <span class="comment"># 生成K个中心质点存放在centr中</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        minJ = <span class="built_in">min</span>(X[:, j])</span><br><span class="line">        rangeJ = <span class="built_in">float</span>(<span class="built_in">max</span>(X[:, j]) - minJ)</span><br><span class="line">        centr[:, j] = minJ + rangeJ * random.rand(k, <span class="number">1</span>)</span><br><span class="line">    c = numpy.array(centr)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;初始中心质点:&#x27;</span>, c)</span><br><span class="line"></span><br><span class="line">    time = <span class="number">0</span>  <span class="comment"># 迭代五次</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> time &lt; <span class="number">5</span>:</span><br><span class="line">        testnum = []  <span class="comment"># 存放测试结果</span></span><br><span class="line">        counts = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]  <span class="comment"># 存放每种结果的数量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X)):</span><br><span class="line">            <span class="comment"># 分配过程</span></span><br><span class="line">            distances = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">                distances[b] = distEclud(c[b], X[i])</span><br><span class="line">            index = distances.index(<span class="built_in">min</span>(distances))</span><br><span class="line">            testnum.append(index)</span><br><span class="line">            counts[index] = counts[index] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            <span class="comment"># 修改中心质点</span></span><br><span class="line">            count = <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X)):</span><br><span class="line">                <span class="keyword">if</span> testnum[m] == i:</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line">                    c[i] = c[i] + X[m]</span><br><span class="line">            c[i] = c[i] / count</span><br><span class="line"></span><br><span class="line">        time = time + <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;第&#x27;</span>, time, <span class="string">&#x27;次修正中心点&#x27;</span>, c)</span><br><span class="line">    <span class="keyword">return</span> testnum</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以直接调用自带聚类器</span></span><br><span class="line"><span class="comment"># estimator = KMeans(n_clusters=3)  # 构造聚类器</span></span><br><span class="line"><span class="comment"># estimator.fit(X)  # 聚类</span></span><br><span class="line"><span class="comment"># label_pred = estimator.labels_  # 获取聚类标签</span></span><br><span class="line"></span><br><span class="line">c = my_kmeans(X, <span class="number">3</span>)</span><br><span class="line">label_pred = numpy.array(c)</span><br><span class="line"><span class="comment"># 绘制k-means结果</span></span><br><span class="line">x0 = X[label_pred == <span class="number">0</span>]</span><br><span class="line">x1 = X[label_pred == <span class="number">1</span>]</span><br><span class="line">x2 = X[label_pred == <span class="number">2</span>]</span><br><span class="line">plt.scatter(x0[:, <span class="number">0</span>], x0[:, <span class="number">1</span>], c=<span class="string">&quot;red&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;种类一&#x27;</span>)</span><br><span class="line">plt.scatter(x1[:, <span class="number">0</span>], x1[:, <span class="number">1</span>], c=<span class="string">&quot;green&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;种类二&#x27;</span>)</span><br><span class="line">plt.scatter(x2[:, <span class="number">0</span>], x2[:, <span class="number">1</span>], c=<span class="string">&quot;blue&quot;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;种类三&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;petal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal width&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">2</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="波士顿房价预测及多元线性回归"><a href="#波士顿房价预测及多元线性回归" class="headerlink" title="波士顿房价预测及多元线性回归"></a>波士顿房价预测及多元线性回归</h1><p>这里使用了三种方法求解</p>
<h2 id="直接使用模型求解"><a href="#直接使用模型求解" class="headerlink" title="直接使用模型求解"></a>直接使用模型求解</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">li = LinearRegression()</span><br><span class="line"><span class="comment"># 拟合数据</span></span><br><span class="line">li.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">y_predict = li.predict(test_x)</span><br></pre></td></tr></table></figure>
<h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><p>公式推导：  </p>
<img src="https://note.youdao.com/yws/api/personal/file/WEB6318832d2e529360507f5fa11e0a26eb?method=download&shareKey=d108136c68d58c43b6851c955ef9c99f" style="zoom:12%"> 

<h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>求解当偏导为0时，β的值<br><img src="https://note.youdao.com/yws/api/personal/file/WEBe2e08b98e77f5ea08b501a8474ded160?method=download&shareKey=8bd56b43e062aac9cdcf50145ba4afc6" style="zoom:60%">  </p>
<p>矩阵求偏公式：<br><img src="https://note.youdao.com/yws/api/personal/file/WEB4b30d2f8d335585cf394cea3348bd2ca?method=download&shareKey=fcb2305e3b030d6595bb669ab0ff2ff7" style="zoom:50%"></p>
<h2 id="全部代码"><a href="#全部代码" class="headerlink" title="全部代码"></a>全部代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">&quot;ignore&quot;</span>)  <span class="comment"># 避免显示FutureWorning</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span></span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line">x = boston[<span class="string">&#x27;data&#x27;</span>]  <span class="comment"># 所有特征信息</span></span><br><span class="line">y = boston[<span class="string">&#x27;target&#x27;</span>]  <span class="comment"># 房价</span></span><br><span class="line">feature_names = boston[<span class="string">&#x27;feature_names&#x27;</span>]  <span class="comment"># 十三个影响因素</span></span><br><span class="line">boston_data = pd.DataFrame(x, columns=feature_names)  <span class="comment"># 特征信息和影响因素</span></span><br><span class="line">boston_data[<span class="string">&#x27;price&#x27;</span>] = y  <span class="comment"># 添加价格列</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">for i in range(13):</span></span><br><span class="line"><span class="string">    plt.figure(figsize=(10, 7))</span></span><br><span class="line"><span class="string">    plt.scatter(x[:,i],y,s=2)#某影响因素的特征信息与房价</span></span><br><span class="line"><span class="string">    plt.title(feature_names[i])</span></span><br><span class="line"><span class="string">plt.show()&#x27;&#x27;&#x27;</span></span><br><span class="line">cor = boston_data.corr()[<span class="string">&#x27;price&#x27;</span>]  <span class="comment"># 求取相关系数</span></span><br><span class="line"><span class="built_in">print</span>(cor)</span><br><span class="line"><span class="comment"># 取相关系数大于0.5的特征值 RM LSTAT PTRATIO price</span></span><br><span class="line"></span><br><span class="line">boston_data = boston_data[[<span class="string">&#x27;LSTAT&#x27;</span>, <span class="string">&#x27;PTRATIO&#x27;</span>, <span class="string">&#x27;RM&#x27;</span>, <span class="string">&#x27;price&#x27;</span>]]  <span class="comment"># 保留该四组因素</span></span><br><span class="line">y = np.array(boston_data[<span class="string">&#x27;price&#x27;</span>])</span><br><span class="line">feature_names = [<span class="string">&#x27;LSTAT&#x27;</span>, <span class="string">&#x27;PTRATIO&#x27;</span>, <span class="string">&#x27;RM&#x27;</span>, <span class="string">&#x27;price&#x27;</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">for i in range(3):</span></span><br><span class="line"><span class="string">    x = np.array(boston_data[feature_names[i]])</span></span><br><span class="line"><span class="string">    var = np.var(x,ddof=1)</span></span><br><span class="line"><span class="string">    cov = np.cov(x,y)[0][1]</span></span><br><span class="line"><span class="string">    k = cov/var</span></span><br><span class="line"><span class="string">    b = np.mean(y) - k*np.mean(x)</span></span><br><span class="line"><span class="string">    y_price = k*x + b</span></span><br><span class="line"><span class="string">    plt.plot(x,y,&#x27;b.&#x27;)</span></span><br><span class="line"><span class="string">    plt.plot(x,y_price,&#x27;k-&#x27;)</span></span><br><span class="line"><span class="string">    plt.show()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">boston_data = boston_data.drop([<span class="string">&#x27;price&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">x = np.array(boston_data)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)  <span class="comment"># 分割训练集和测试集</span></span><br><span class="line"><span class="comment"># 直接使用模型求解</span></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">li = LinearRegression()</span><br><span class="line"><span class="comment"># 拟合数据</span></span><br><span class="line">li.fit(train_x, train_y)</span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">y_predict = li.predict(test_x)</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plt.plot(y_predict, <span class="string">&#x27;b-&#x27;</span>)</span><br><span class="line">plt.plot(test_y, <span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;predict&#x27;</span>, <span class="string">&#x27;true&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;直接使用模型&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line">mes = metrics.mean_squared_error(y_predict, test_y)</span><br><span class="line"><span class="comment">#print(mes)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最小二乘法求解</span></span><br><span class="line">boston_data.insert(loc=<span class="number">0</span>, column=<span class="string">&#x27;one&#x27;</span>, value=<span class="number">1</span>)</span><br><span class="line">x = np.array(boston_data)</span><br><span class="line">train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)  <span class="comment"># 分割训练集和测试集</span></span><br><span class="line">xT = x.T</span><br><span class="line">x_mat = np.mat(train_x)</span><br><span class="line">y_mat = np.mat(train_y).T</span><br><span class="line">xT = x_mat.T</span><br><span class="line">B = (xT * x_mat).I * xT * y_mat</span><br><span class="line">y_predict = test_x * B</span><br><span class="line">plt2 = plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plt2 = plt.plot(y_predict, <span class="string">&#x27;b-&#x27;</span>)</span><br><span class="line">plt2 = plt.plot(test_y, <span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">plt2 = plt.legend([<span class="string">&#x27;predict&#x27;</span>, <span class="string">&#x27;true&#x27;</span>])</span><br><span class="line">plt2 = plt.title(<span class="string">&#x27;最小二乘法&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多元线性回归</span></span><br><span class="line">x = np.array(boston_data)</span><br><span class="line">train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">0</span>)  <span class="comment"># 分割训练集和测试集</span></span><br><span class="line">xT = x.T</span><br><span class="line">x_mat = np.mat(train_x)</span><br><span class="line">y_mat = np.mat(train_y).T</span><br><span class="line">xT = x_mat.T</span><br><span class="line">B = [[<span class="number">22.1768</span>], [-<span class="number">0.5576</span>], [-<span class="number">1.11165</span>], [<span class="number">4.44512</span>]]</span><br><span class="line">B = np.mat(B)</span><br><span class="line">Bp = -<span class="number">2</span> * xT * (y_mat - x_mat * B)  <span class="comment"># 即B的偏导</span></span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    B = B - <span class="number">0.000005</span> * Bp</span><br><span class="line">    Bp = -<span class="number">2</span> * xT * (y_mat - x_mat * B)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">        <span class="built_in">sum</span> += <span class="built_in">abs</span>(Bp[i])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">sum</span> &lt;= <span class="number">0.00001</span>: <span class="keyword">break</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最终B：&quot;</span>, B)</span><br><span class="line"></span><br><span class="line">y_predict = test_x * B</span><br><span class="line">plt3 = plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">plt3 = plt.plot(y_predict, <span class="string">&#x27;b-&#x27;</span>)</span><br><span class="line">plt3 = plt.plot(test_y, <span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">plt3 = plt.legend([<span class="string">&#x27;predict&#x27;</span>, <span class="string">&#x27;true&#x27;</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;多元线性回归&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p>Module类是nn模块里提供的一个模型构造类，是所有神经网络模块的基类，我们可以继承它来定义我们想要的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn     <span class="comment"># 导入nn模块</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sample</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Sample, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>),     <span class="comment"># 卷积层</span></span><br><span class="line">            nn.Sigmoid(),     <span class="comment"># 激活函数</span></span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>),     <span class="comment"># 最大池化层</span></span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">14</span>*<span class="number">14</span>, <span class="number">10</span>),     <span class="comment"># 全连接层</span></span><br><span class="line">            nn.Sigmoid(),     <span class="comment"># 激活函数</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span>     <span class="comment"># 定义前向计算</span></span><br><span class="line">        feature = self.conv(img)     <span class="comment"># 卷积层</span></span><br><span class="line">        output = self.fc(feature.view(img.shape[<span class="number">0</span>], -<span class="number">1</span>))     <span class="comment"># 全连接层</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p>我们将 Sample 的实例对象打印出来就可以清楚地看到上面代码中搭建出的模型的整体结构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Sample(</span><br><span class="line">  (conv): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): Sigmoid()</span><br><span class="line">    (<span class="number">2</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (fc): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">196</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">1</span>): Sigmoid()</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">acodey</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://acodey.github.io/2022/01/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">https://acodey.github.io/2022/01/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://acodey.github.io" target="_blank">Acodey</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&amp;shareKey=53d190ab6364e8ed3008a3309d8bdb67" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/03/31/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2-DTC/"><img class="prev-cover" src="https://note.youdao.com/yws/api/personal/file/WEBa91ac9f73616f8a525d36fb7861278e9?method=getImage&amp;version=79&amp;cstk=c8MhR8Y_" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">图像分割-DTC</div></div></a></div><div class="next-post pull-right"><a href="/2022/01/12/this-is-a-test/"><img class="next-cover" src="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&amp;shareKey=53d190ab6364e8ed3008a3309d8bdb67" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">this is a test</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://w.wallhaven.cc/full/wq/wallhaven-wqe1rq.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">acodey</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">真不吃香菜</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E4%B8%8E%E9%A2%84%E6%B5%8B"><span class="toc-number">1.</span> <span class="toc-text">矩阵分解与预测</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.1.</span> <span class="toc-text">构建损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E8%8E%B7%E5%BE%97%E4%BF%AE%E6%AD%A3%E7%9A%84p%E5%92%8Cq%E5%88%86%E9%87%8F"><span class="toc-number">1.2.</span> <span class="toc-text">通过梯度下降法获得修正的p和q分量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%AD%E4%BB%A3%E7%AE%97%E6%B3%95%E6%B1%82%E5%BE%97R%E2%80%99%E5%8F%8A%E7%BB%98%E5%88%B6%E6%94%B6%E6%95%9B%E6%9B%B2%E7%BA%BF%E5%9B%BE"><span class="toc-number">1.3.</span> <span class="toc-text">迭代算法求得R’及绘制收敛曲线图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81"><span class="toc-number">1.4.</span> <span class="toc-text">实现代码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%8F%8A%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">逻辑回归及鸢尾花分类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%8B%E5%B7%A5%E6%8E%A8%E5%AF%BC%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.1.</span> <span class="toc-text">手工推导逻辑回归梯度下降实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%A7%8D%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B"><span class="toc-number">2.1.1.</span> <span class="toc-text">第二种推导过程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB"><span class="toc-number">2.2.</span> <span class="toc-text">用逻辑回归实现鸢尾花分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">2.3.</span> <span class="toc-text">运行结果</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">3.</span> <span class="toc-text">一元线性回归与梯度下降</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%8B%E5%B7%A5%E6%8E%A8%E5%AF%BC"><span class="toc-number">3.1.</span> <span class="toc-text">手工推导</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%99%E9%87%8C%E6%B3%A8%E6%84%8F%E5%9C%A8%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE%E6%97%B6%EF%BC%8C%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%AE%9C%E8%BF%87%E5%A4%A7"><span class="toc-number">3.1.1.</span> <span class="toc-text">这里注意在处理数据时，数据不宜过大</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.2.</span> <span class="toc-text">作业的代码实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#KNN%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E5%8F%8A%E6%B5%8B%E8%AF%95%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">4.</span> <span class="toc-text">KNN分类算法及测试鸢尾花数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4"><span class="toc-number">4.1.</span> <span class="toc-text">算法步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%88%86%E5%89%B2%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">4.1.1.</span> <span class="toc-text">1.分割数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%AE%A1%E7%AE%97%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%AD%E7%9A%84%E6%AF%8F%E4%B8%80%E4%B8%AA%E5%85%83%E7%B4%A0%E5%88%B0%E8%AE%AD%E7%BB%83%E9%9B%86%E6%89%80%E6%9C%89%E5%85%83%E7%B4%A0%E4%B8%AD%E6%9C%80%E8%BF%91%E7%9A%84p%E4%B8%AA%E5%85%83%E7%B4%A0"><span class="toc-number">4.1.2.</span> <span class="toc-text">2.计算测试集中的每一个元素到训练集所有元素中最近的p个元素</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%B0%86%E8%BF%99p%E4%B8%AA%E5%85%83%E7%B4%A0%E7%9A%84%E7%B1%BB%E5%88%AB%E7%9A%84%E6%95%B0%E9%87%8F%E8%BF%9B%E8%A1%8C%E6%8E%92%E5%BA%8F%EF%BC%8C%E6%95%B0%E9%87%8F%E6%9C%80%E5%A4%9A%E7%9A%84%E8%AE%BE%E5%AE%9A%E4%B8%BA%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E5%85%83%E7%B4%A0%E7%9A%84%E7%B1%BB%E5%88%AB"><span class="toc-number">4.1.3.</span> <span class="toc-text">3.将这p个元素的类别的数量进行排序，数量最多的设定为测试集的元素的类别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%BE%AA%E7%8E%AF%EF%BC%8C%E9%A2%84%E6%B5%8B%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E6%89%80%E6%9C%89%E5%85%83%E7%B4%A0"><span class="toc-number">4.1.4.</span> <span class="toc-text">4.循环，预测测试集的所有元素</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="toc-number">4.2.</span> <span class="toc-text">完整代码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E5%8F%8A%E6%B5%8B%E8%AF%95%E9%B8%A2%E5%B0%BE%E8%8A%B1%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">5.</span> <span class="toc-text">K-means聚类算法及测试鸢尾花数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%90%86%E8%AE%BA"><span class="toc-number">5.1.</span> <span class="toc-text">理论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E6%88%90k%E4%B8%AA%E4%B8%AD%E5%BF%83%E8%B4%A8%E7%82%B9%EF%BC%88%E5%8F%8Ak%E4%B8%AA%E7%B0%87%EF%BC%89"><span class="toc-number">5.1.1.</span> <span class="toc-text">生成k个中心质点（及k个簇）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E5%88%86%E9%85%8D%EF%BC%9A"><span class="toc-number">5.1.2.</span> <span class="toc-text">样本分配：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E5%90%84%E4%B8%AA%E7%B0%87%E7%9A%84%E4%B8%AD%E5%BF%83%E8%B4%A8%E7%82%B9"><span class="toc-number">5.1.3.</span> <span class="toc-text">更新各个簇的中心质点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%AA%E7%8E%AF%E7%AC%AC%E4%BA%8C%E6%AD%A5%E5%92%8C%E7%AC%AC%E4%B8%89%E6%AD%A5"><span class="toc-number">5.1.4.</span> <span class="toc-text">循环第二步和第三步</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%93%E4%B8%AD%E5%BF%83%E8%B4%A8%E7%82%B9%E6%B2%A1%E6%9C%89%E6%9B%B4%E6%96%B0%E6%88%96%E8%80%85%E6%89%93%E5%88%B0%E7%BA%A6%E6%9D%9F%E6%AC%A1%E6%95%B0%E5%90%8E%EF%BC%8C%E5%81%9C%E6%AD%A2%E5%BE%AA%E7%8E%AF"><span class="toc-number">5.1.5.</span> <span class="toc-text">当中心质点没有更新或者打到约束次数后，停止循环</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">5.2.</span> <span class="toc-text">代码实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B%E5%8F%8A%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">6.</span> <span class="toc-text">波士顿房价预测及多元线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9E%8B%E6%B1%82%E8%A7%A3"><span class="toc-number">6.1.</span> <span class="toc-text">直接使用模型求解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">6.2.</span> <span class="toc-text">多元线性回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"><span class="toc-number">6.3.</span> <span class="toc-text">最小二乘法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81"><span class="toc-number">6.4.</span> <span class="toc-text">全部代码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">7.</span> <span class="toc-text">卷积神经网络</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/04/01/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90UNet%E5%92%8CUnet/" title="深度解析UNet和Unet++"><img src="https://note.youdao.com/yws/api/personal/file/WEBc4ce335d30f24fcff055d089ce84905e?method=getImage&amp;version=78&amp;cstk=c8MhR8Y_" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深度解析UNet和Unet++"/></a><div class="content"><a class="title" href="/2022/04/01/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90UNet%E5%92%8CUnet/" title="深度解析UNet和Unet++">深度解析UNet和Unet++</a><time datetime="2022-04-01T08:10:33.000Z" title="发表于 2022-04-01 16:10:33">2022-04-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/31/CNN%E8%AF%A6%E8%A7%A3/" title="CNN详解"><img src="https://note.youdao.com/yws/api/personal/file/WEBb9da70619c8163bb375fb1d6de66cea1?method=download&amp;shareKey=2732d7c491629102d61965cc72d9504d" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN详解"/></a><div class="content"><a class="title" href="/2022/03/31/CNN%E8%AF%A6%E8%A7%A3/" title="CNN详解">CNN详解</a><time datetime="2022-03-31T08:59:57.000Z" title="发表于 2022-03-31 16:59:57">2022-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/31/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CFCN/" title="全卷积网络FCN"><img src="https://note.youdao.com/yws/api/personal/file/WEBb9da70619c8163bb375fb1d6de66cea1?method=download&amp;shareKey=2732d7c491629102d61965cc72d9504d" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="全卷积网络FCN"/></a><div class="content"><a class="title" href="/2022/03/31/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9CFCN/" title="全卷积网络FCN">全卷积网络FCN</a><time datetime="2022-03-31T08:42:57.000Z" title="发表于 2022-03-31 16:42:57">2022-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/31/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2-DTC/" title="图像分割-DTC"><img src="https://note.youdao.com/yws/api/personal/file/WEBa91ac9f73616f8a525d36fb7861278e9?method=getImage&amp;version=79&amp;cstk=c8MhR8Y_" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图像分割-DTC"/></a><div class="content"><a class="title" href="/2022/03/31/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2-DTC/" title="图像分割-DTC">图像分割-DTC</a><time datetime="2022-03-31T08:14:45.000Z" title="发表于 2022-03-31 16:14:45">2022-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="机器学习"><img src="https://note.youdao.com/yws/api/personal/file/WEB086a45e71dce2885c98784001b1d0697?method=download&amp;shareKey=53d190ab6364e8ed3008a3309d8bdb67" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="机器学习"/></a><div class="content"><a class="title" href="/2022/01/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" title="机器学习">机器学习</a><time datetime="2022-01-12T16:23:28.000Z" title="发表于 2022-01-13 00:23:28">2022-01-13</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 By acodey</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Cause that's what I said I would do from the start.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>